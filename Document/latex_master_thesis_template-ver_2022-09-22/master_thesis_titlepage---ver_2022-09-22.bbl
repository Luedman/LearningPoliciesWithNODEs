\begin{thebibliography}{10}

\bibitem{barto1983neuronlike}
Andrew~G Barto, Richard~S Sutton, and Charles~W Anderson.
\newblock Neuronlike adaptive elements that can solve difficult learning
  control problems.
\newblock {\em IEEE transactions on systems, man, and cybernetics},
  (5):834--846, 1983.

\bibitem{bellman1957markovian}
Richard Bellman.
\newblock A markovian decision process.
\newblock {\em Journal of mathematics and mechanics}, pages 679--684, 1957.

\bibitem{bertsekas1996neuro}
Dimitri Bertsekas and John~N Tsitsiklis.
\newblock {\em Neuro-dynamic programming}.
\newblock Athena Scientific, 1996.

\bibitem{gymref}
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman,
  Jie Tang, and Wojciech Zaremba.
\newblock Openai gym, 2016.

\bibitem{chen2018neural}
Ricky~TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural ordinary differential equations.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{chen2022energy}
Zheng Chen, Hongji Gu, Shiquan Shen, and Jiangwei Shen.
\newblock Energy management strategy for power-split plug-in hybrid electric
  vehicle based on mpc and double q-learning.
\newblock {\em Energy}, 245:123182, 2022.

\bibitem{dupont2019augmented}
Emilien Dupont, Arnaud Doucet, and Yee~Whye Teh.
\newblock Augmented neural odes.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{hasselt2010double}
Hado Hasselt.
\newblock Double q-learning.
\newblock {\em Advances in neural information processing systems}, 23, 2010.

\bibitem{he2021variational}
Zhimin He, Lvzhou Li, Shenggen Zheng, Yongyao Li, and Haozhen Situ.
\newblock Variational quantum compiling with double q-learning.
\newblock {\em New Journal of Physics}, 23(3):033002, 2021.

\bibitem{jian2016deep}
S~Jian, H~Kaiming, R~Shaoqing, and Z~Xiangyu.
\newblock Deep residual learning for image recognition.
\newblock In {\em IEEE Conference on Computer Vision \& Pattern Recognition},
  pages 770--778, 2016.

\bibitem{li2020onboard}
Kai Li, Wei Ni, Bo~Wei, and Eduardo Tovar.
\newblock Onboard double q-learning for airborne data capture in wireless
  powered iot networks.
\newblock {\em IEEE Networking Letters}, 2(2):71--75, 2020.

\bibitem{lin2018resnet}
Hongzhou Lin and Stefanie Jegelka.
\newblock Resnet with one-neuron hidden layers is a universal approximator.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{lin1992self}
Long-Ji Lin.
\newblock Self-improving reactive agents based on reinforcement learning,
  planning and teaching.
\newblock {\em Machine learning}, 8:293--321, 1992.

\bibitem{liu2019double}
Zheng Liu and Shiva Abbaszadeh.
\newblock Double q-learning for radiation source detection.
\newblock {\em Sensors}, 19(4):960, 2019.

\bibitem{march1991exploration}
James~G March.
\newblock Exploration and exploitation in organizational learning.
\newblock {\em Organization science}, 2(1):71--87, 1991.

\bibitem{mnih2013playing}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1312.5602}, 2013.

\bibitem{pontryagin1987mathematical}
Lev~Semenovich Pontryagin.
\newblock {\em Mathematical theory of optimal processes}.
\newblock CRC press, 1987.

\bibitem{rezende2015variational}
Danilo Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In {\em International conference on machine learning}, pages
  1530--1538. PMLR, 2015.

\bibitem{riedmiller2005neural}
Martin Riedmiller.
\newblock Neural fitted q iteration--first experiences with a data efficient
  neural reinforcement learning method.
\newblock In {\em Machine Learning: ECML 2005: 16th European Conference on
  Machine Learning, Porto, Portugal, October 3-7, 2005. Proceedings 16}, pages
  317--328. Springer, 2005.

\bibitem{rummery1994line}
Gavin~A Rummery and Mahesan Niranjan.
\newblock {\em On-line Q-learning using connectionist systems}, volume~37.
\newblock University of Cambridge, Department of Engineering Cambridge, UK,
  1994.

\bibitem{sander2022residual}
Michael Sander, Pierre Ablin, and Gabriel Peyr{\'e}.
\newblock Do residual neural networks discretize neural ordinary differential
  equations?
\newblock {\em Advances in Neural Information Processing Systems},
  35:36520--36532, 2022.

\bibitem{schaul2015prioritized}
Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver.
\newblock Prioritized experience replay.
\newblock {\em arXiv preprint arXiv:1511.05952}, 2015.

\bibitem{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em nature}, 529(7587):484--489, 2016.

\bibitem{sutton1988learning}
Richard~S Sutton.
\newblock Learning to predict by the methods of temporal differences.
\newblock {\em Machine learning}, 3:9--44, 1988.

\bibitem{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem{sutton1999policy}
Richard~S Sutton, David McAllester, Satinder Singh, and Yishay Mansour.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock {\em Advances in neural information processing systems}, 12, 1999.

\bibitem{szepesvari2009reinforcement}
Csaba Szepesv{\'a}ri.
\newblock Reinforcement learning algorithms for mdps.
\newblock 2009.

\bibitem{tsitsiklis1996analysis}
John Tsitsiklis and Benjamin Van~Roy.
\newblock Analysis of temporal-diffference learning with function
  approximation.
\newblock {\em Advances in neural information processing systems}, 9, 1996.

\bibitem{van2016deep}
Hado Van~Hasselt, Arthur Guez, and David Silver.
\newblock Deep reinforcement learning with double q-learning.
\newblock In {\em Proceedings of the AAAI conference on artificial
  intelligence}, 2016.

\bibitem{watkins1992q}
Christopher~JCH Watkins and Peter Dayan.
\newblock Q-learning.
\newblock {\em Machine learning}, 8:279--292, 1992.

\bibitem{zhang2018human}
Yi~Zhang, Ping Sun, Yuhan Yin, Lin Lin, and Xuesong Wang.
\newblock Human-like autonomous vehicle speed control by deep reinforcement
  learning with double q-learning.
\newblock In {\em 2018 IEEE intelligent vehicles symposium (IV)}, pages
  1251--1256. IEEE, 2018.

\end{thebibliography}
