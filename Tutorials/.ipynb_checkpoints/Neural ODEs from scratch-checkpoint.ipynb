{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19eb5d3a",
   "metadata": {},
   "source": [
    "Source http://implicit-layers-tutorial.org/neural_odes/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8440d",
   "metadata": {},
   "source": [
    "## Chapter 1\n",
    "Fixed Point Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd1d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beaf2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhFixedPointLayer(nn.Module):\n",
    "    def __init__(self, out_features, tol= 1e-4, max_iter=50):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(out_features, out_features, bias=False)\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # initialize output z to be zero\n",
    "        z = torch.zeros_like(x)\n",
    "        self.iterations = 0\n",
    "        \n",
    "        while self.iterations < self.max_iter:\n",
    "            z_next = torch.tanh(self.linear(z) + x)\n",
    "            self.err = torch.norm(z - z_next)\n",
    "            z = z_next\n",
    "            self.iterations += 1\n",
    "            \n",
    "            if self.err < self.tol:\n",
    "                break\n",
    "                \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = TanhFixedPointLayer(50)\n",
    "X = torch.randn(10, 50)\n",
    "Z = layer(X)\n",
    "print(f\"Terminated after {layer.iterations} iterations with error {layer.err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd319e",
   "metadata": {},
   "source": [
    "MNIST DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf858e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb806c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(\".\", train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(\".\", train=False, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(mnist_train, batch_size = 100, shuffle = True)\n",
    "test_loader = DataLoader(mnist_test, batch_size = 100, shuffle = True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Flatten(), \n",
    "                      nn.Linear(784, 100),\n",
    "                      TanhFixedPointLayer(100, max_iter=200),\n",
    "                      nn.Linear(100, 10)).to(device)\n",
    "opt = optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(loader, model, opt=None, monitor=None):\n",
    "    total_loss, total_err, total_monitor = 0.,0.,0.\n",
    "    model.eval() if opt is None else model.train()\n",
    "    for X,y in tqdm(loader, leave=False):\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        yp = model(X)\n",
    "        loss = nn.CrossEntropyLoss()(yp,y)\n",
    "        if opt:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            if sum(torch.sum(torch.isnan(p.grad)) for p in model.parameters()) == 0:\n",
    "                opt.step()\n",
    "        \n",
    "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
    "        total_loss += loss.item() * X.shape[0]\n",
    "        if monitor is not None:\n",
    "            total_monitor += monitor(model)\n",
    "    return total_err / len(loader.dataset), total_loss / len(loader.dataset), total_monitor / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8017dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i == 5:\n",
    "        opt.param_groups[0][\"lr\"] = 1e-2\n",
    "\n",
    "    train_err, train_loss, train_fpiter = epoch(train_loader, model, opt, lambda x : x[2].iterations)\n",
    "    test_err, test_loss, test_fpiter = epoch(test_loader, model, monitor = lambda x : x[2].iterations)\n",
    "    print(f\"Train Error: {train_err:.4f}, Loss: {train_loss:.4f}, FP Iters: {train_fpiter:.2f} | \" +\n",
    "          f\"Test Error: {test_err:.4f}, Loss: {test_loss:.4f}, FP Iters: {test_fpiter:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455219d3",
   "metadata": {},
   "source": [
    "Tanh Newton Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhNewtonLayer(nn.Module):\n",
    "    def __init__(self, out_features, tol = 1e-4, max_iter=50):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(out_features, out_features, bias=False)\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "  \n",
    "    def forward(self, x):\n",
    "\n",
    "        # initialize output z to be zero\n",
    "        z = torch.tanh(x)\n",
    "        self.iterations = 0\n",
    "    \n",
    "        # iterate until convergence\n",
    "        while self.iterations < self.max_iter:\n",
    "            z_linear = self.linear(z) + x\n",
    "            g = z - torch.tanh(z_linear)\n",
    "            self.err = torch.norm(g)\n",
    "            if self.err < self.tol:\n",
    "                break\n",
    "\n",
    "            # newton step #ToDo: Fix this\n",
    "            a = torch.eye(z.shape[1])[None,:,:]\n",
    "            b = (1 / torch.cosh(z_linear)**2)[:,:,None]\n",
    "            c = self.linear.weight[None,:,:]\n",
    "            #print(f\"a: {a.shape}, b: {b.shape}, c: {c.shape}, b*c {(b * c).shape}\")\n",
    "            \n",
    "            J =  a - b * c \n",
    "            z = z - torch.linalg.solve(J, g[:,:,None])[0][:,0]\n",
    "            self.iterations += 1\n",
    "\n",
    "        g = z - torch.tanh(self.linear(z) + x)\n",
    "        z[torch.norm(g,dim=1) > self.tol,:] = 0\n",
    "        return z                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = TanhNewtonLayer(50)\n",
    "X = torch.randn(10, 50)\n",
    "Z = layer(X)\n",
    "print(f\"Termiated after {layer.iterations} iterations with error {layer.err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20330ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc5405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhNewtonImplicitLayer(nn.Module):\n",
    "    def __init__(self, out_features, tol = 1e-4, max_iter=50):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(out_features, out_features, bias=False)\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "  \n",
    "    def forward(self, x):\n",
    "        # Run Newton's method outside of the autograd framework\n",
    "        with torch.no_grad():\n",
    "            z = torch.tanh(x)\n",
    "            self.iterations = 0\n",
    "            while self.iterations < self.max_iter:\n",
    "                z_linear = self.linear(z) + x\n",
    "                g = z - torch.tanh(z_linear)\n",
    "                self.err = torch.norm(g)\n",
    "                if self.err < self.tol:\n",
    "                    break\n",
    "\n",
    "                # newton step\n",
    "                a = torch.eye(z.shape[1])[None,:,:]\n",
    "                b = (1 / torch.cosh(z_linear)**2)[:,:,None]\n",
    "                c = self.linear.weight[None,:,:]\n",
    "                J = a - b * c\n",
    "                \n",
    "                z = z - torch.linalg.solve(J, g[:,:,None])[0][:,0]\n",
    "                self.iterations += 1\n",
    "    \n",
    "        # reengage autograd and add the gradient hook\n",
    "        z = torch.tanh(self.linear(z) + x)\n",
    "            \n",
    "        z.register_hook(lambda grad: torch.linalg.solve(J.transpose(1,2), grad[:,:,None])[:,:, 0])\n",
    "        return z       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368adf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model = nn.Sequential(nn.Flatten(),\n",
    "                      nn.Linear(784, 100),\n",
    "                      TanhNewtonImplicitLayer(100, max_iter=40),\n",
    "                      nn.Linear(100, 10)\n",
    "                      ).to(device)\n",
    "opt = optim.SGD(model.parameters(), lr=1e-1)\n",
    "\n",
    "for i in range(10):\n",
    "    if i == 5:\n",
    "        opt.param_groups[0][\"lr\"] = 1e-2\n",
    "\n",
    "    train_err, train_loss, train_fpiter = epoch(train_loader, model, opt, lambda x : x[2].iterations)\n",
    "    test_err, test_loss, test_fpiter = epoch(test_loader, model, monitor = lambda x : x[2].iterations)\n",
    "    print(f\"Train Error: {train_err:.4f}, Loss: {train_loss:.4f}, Newton Iters: {train_fpiter:.2f} | \" +\n",
    "          f\"Test Error: {test_err:.4f}, Loss: {test_loss:.4f}, Newton Iters: {test_fpiter:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edf5ebe",
   "metadata": {},
   "source": [
    "## Chapter 2\n",
    "Implicit functions and automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345ac6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "def fwd_solver(f, z_init):\n",
    "    z_prev, z = z_init, f(z_init)\n",
    "    while jnp.linalg.norm(z_prev - z) > 1e-5:\n",
    "        z_prev, z = z, f(z)\n",
    "    return z\n",
    "\n",
    "def newton_solver(f, z_init):\n",
    "    f_root = lambda z: f(z) - z\n",
    "    g = lambda z: z - jnp.linalg.solve(jax.jacobian(f_root)(z), f_root(z))\n",
    "    return fwd_solver(g, z_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a93f0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_point_layer(solver, f, params, x):\n",
    "    z_star = solver(lambda z: f(params, x, z), z_init=jnp.zeros_like(x))\n",
    "    return z_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a0aeb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda W, x, z: jnp.tanh(jnp.dot(W, z) + x)\n",
    "\n",
    "ndim = 10\n",
    "W = jax.random.normal(jax.random.PRNGKey(0), (ndim, ndim)) / jnp.sqrt(ndim)\n",
    "x = jax.random.normal(jax.random.PRNGKey(1), (ndim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2575c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00649598 -0.70159584 -0.984715   -0.04196559 -0.6152218  -0.4818382\n",
      "  0.5783123   0.9556704  -0.08373147  0.8447805 ]\n",
      "[ 0.00649408 -0.701595   -0.98471504 -0.04196503 -0.61522114 -0.48183843\n",
      "  0.57831246  0.9556705  -0.08372927  0.8447799 ]\n"
     ]
    }
   ],
   "source": [
    "z_star = fixed_point_layer(fwd_solver, f, W, x)\n",
    "print(z_star)\n",
    "\n",
    "z_star = fixed_point_layer(newton_solver, f, W, x)\n",
    "print(z_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c4c9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00756674 -0.8125901  -1.1404794  -0.04861291 -0.7125524  -0.55805546\n",
      "  0.6697881   1.1068413  -0.09702272  0.9784225 ]\n",
      "[ 0.00752132 -0.81257427 -1.1404786  -0.04860311 -0.71253765 -0.55805624\n",
      "  0.66979074  1.1068397  -0.09697367  0.9784084 ]\n"
     ]
    }
   ],
   "source": [
    "g = jax.grad(lambda W: fixed_point_layer(fwd_solver, f, W, x).sum())(W)\n",
    "print(g[0])\n",
    "\n",
    "g = jax.grad(lambda W: fixed_point_layer(newton_solver, f, W, x).sum())(W)\n",
    "print(g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4de6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeacac09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbad092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd1a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670fd028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593d819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22094bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "from jax import jit, grad, vmap\n",
    "from jax.experimental.ode import odeint\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26600763",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ddfdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(params, inputs):\n",
    "    for w, b in params:\n",
    "        outputs = jnp.dot(inputs, w) + b\n",
    "        inputs = jnp.tanh(outputs)\n",
    "    return outputs\n",
    "\n",
    "def resnet(params, inputs, depth):\n",
    "    for i in range(depth):\n",
    "        outputs = mlp(params, inputs) + inputs\n",
    "    return outputs\n",
    "\n",
    "def resnet_squared_loss(params, inputs,  targets):\n",
    "    preds = resnet(params, inputs, resnet_depth)\n",
    "    return jnp.mean(jnp.sum((preds - targets)**2, axis=1))\n",
    "\n",
    "def init_random_params(scale, layer_sizes, rng=npr.RandomState(0)):\n",
    "    params = []\n",
    "    for m, n in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "        params += [((scale * rng.randn(m, n)), scale * rng.randn(n))]\n",
    "    return params\n",
    "\n",
    "@jit\n",
    "def resnet_update(params, inputs, targets, step_size):\n",
    "    grads = grad(resnet_squared_loss)(params, inputs, targets)\n",
    "    update = []\n",
    "    for (w, b), (dw, db) in zip(params, grads):\n",
    "        update += [(w - step_size * dw, b - step_size * db)]\n",
    "    return update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6359797a",
   "metadata": {},
   "source": [
    "Toy 1D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy 1D dataset\n",
    "inputs = jnp.reshape(jnp.linspace(-2.0, 2.0, 10), (10, 1))\n",
    "fine_inputs = jnp.reshape(jnp.linspace(-3.0, 3.0, 100), (100,1))\n",
    "targets = inputs**3 + 0.1 * inputs\n",
    "\n",
    "# Hyperparameters\n",
    "layer_sizes = [1, 20, 1]\n",
    "param_scale = 1.0\n",
    "step_size = 0.01\n",
    "train_iters = 1000\n",
    "\n",
    "# Init and train\n",
    "resnet_params = init_random_params(param_scale, layer_sizes)\n",
    "for i in range(train_iters):\n",
    "    resnet_params = resnet_update(resnet_params, inputs,\n",
    "                                  targets, step_size)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(6,4), dpi=150)\n",
    "ax = fig.gca()\n",
    "ax.scatter(inputs, targets, lw=0.5, color=\"green\")\n",
    "\n",
    "ax.plot(fine_inputs, resnet(resnet_params, fine_inputs, resnet_depth),\n",
    "        lw=0.5, color=\"blue\")\n",
    "ax.set_xlabel('input')\n",
    "ax.set_ylabel('output')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9211984",
   "metadata": {},
   "source": [
    "Neural ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7396c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_dynamics(state, time, params):\n",
    "    state_and_time = jnp.hstack([state, jnp.array(time)])\n",
    "    return mlp(params, state_and_time)\n",
    "\n",
    "def odenet(params, inputs):\n",
    "    start_and_end_times = jnp.array([0.0, 1.0])\n",
    "    init_state, final_state = odeint(nn_dynamics, inputs,\n",
    "                                     start_and_end_times, params)\n",
    "    return final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c23c5f",
   "metadata": {},
   "source": [
    "Train an neural ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acacd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_odenet = vmap(odenet, in_axes=(None, 0))\n",
    "odenet_layer_sizes = [2, 20, 1]\n",
    "\n",
    "def odenet_loss(params, inputs, targets):\n",
    "    preds = batched_odenet(params, inputs)\n",
    "    return jnp.mean(jnp.sum((preds - targets)**2, axis=1))\n",
    "\n",
    "def ode_net_update(params, inputs, targets, step_size):\n",
    "    grads = grad(odenet_loss)(params, inputs, targets)\n",
    "    updates = []\n",
    "    for (w, b), (dw, db) in zip(params, grads):\n",
    "        updates += [(w - step_size*dw, b - step_size*db)]\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6083dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    odenet_params = init_random_params(param_scale, odenet_layer_sizes)\n",
    "\n",
    "    for i in range(train_iters):\n",
    "        odenet_params = ode_net_update(odenet_params, inputs,\n",
    "                                       targets, step_size)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 4), dpi=150)\n",
    "    ax = fig.gca()\n",
    "    ax.scatter(inputs, targets, lw=0.5, color=\"green\")\n",
    "    ax.plot(fine_inputs, resnet(resnet_params, fine_inputs, resnet_depth),\n",
    "            lw=0.5, color='blue')\n",
    "    ax.plot(fine_inputs, batched_odenet(odenet_params, fine_inputs),\n",
    "            lw=0.5, color='red')\n",
    "    ax.set_xlabel('input')\n",
    "    ax.set_ylabel('output')\n",
    "    plt.legend(('Resnet predictions', 'ODE Net predictions'))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883fa52e",
   "metadata": {},
   "source": [
    "Activation Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b853550",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    times = jnp.linspace(0.0, 1.0, 200)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 4), dpi=150)\n",
    "    ax = fig.gca()\n",
    "\n",
    "    @jit\n",
    "    def odenet_times(params, inputs, times):\n",
    "        def dynamics_func(state, time, params):\n",
    "            return mlp(params, jnp.hstack([state, jnp.array(time)]))\n",
    "        return odeint(dynamics_func, inputs, times, params)\n",
    "\n",
    "    for i in fine_inputs:\n",
    "        ax.plot(odenet_times(odenet_params, i, times), times, lw=0.5)\n",
    "\n",
    "    ax.set_xlabel('input / output')\n",
    "    ax.set_ylabel('time / depth')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10428f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discrete_q_table(no_oberservation_bins, no_actions_bins, env):\n",
    "    \n",
    "    obs_space_size = len(env.observation_space.high)\n",
    "    Q_bins = [jnp.linspace(env.observation_space.low[i], env.observation_space.high[i], no_oberservation_bins) for\n",
    "              i in range(obs_space_size)]\n",
    "    \n",
    "    Q_table = np.random.uniform(low=env.action_space.low[0]-np.abs(env.action_space.low[0]*2),\n",
    "                                high=env.action_space.low[0],\n",
    "                               size=([no_oberservation_bins] * obs_space_size + [no_actions_bins]))\n",
    "    \n",
    "    #Q_table = np.zeros(shape=([no_oberservation_bins] * obs_space_size + [no_actions_bins]))\n",
    "    \n",
    "    return Q_bins, Q_table\n",
    "\n",
    "def create_discrete_action_space(num_bins, env):\n",
    "    \n",
    "    action_space_bins = [jnp.linspace(env.action_space.low[i], env.action_space.high[i], num_bins) for\n",
    "                         i in range(len(env.action_space.high))]\n",
    "    \n",
    "    return action_space_bins[0]\n",
    "\n",
    "def discretize_state(state, bins):\n",
    "    stateIndex = []\n",
    "    for i in range(len(state)):\n",
    "        stateIndex.append(np.digitize(state[i], bins[i]) - 1)\n",
    "    return tuple(stateIndex)\n",
    "\n",
    "def discretize_actions(action, bins):\n",
    "    return np.digitize(action, bins) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be5099",
   "metadata": {},
   "outputs": [],
   "source": [
    "enviroment = gym.make(\"MountainCarContinuous-v0\", render_mode=\"human\")\n",
    "observation, info = enviroment.reset(seed=42)\n",
    "\n",
    "no_actions_bins = 5\n",
    "no_oberservation_bins = 20\n",
    "action_bins = create_discrete_action_space(no_actions_bins, enviroment)\n",
    "obs_bins, Q_table = create_discrete_q_table(no_oberservation_bins, no_actions_bins, enviroment)\n",
    "\n",
    "sim_params = {\"env\": enviroment,\n",
    "              \"no_epochs\": 250,\n",
    "              \"no_iterations\": 10000,\n",
    "              \"no_oberservation_bins\": no_oberservation_bins,\n",
    "              \"no_actions_bins\": no_actions_bins, \n",
    "              \"epsilon\": 0.8, \n",
    "              \"action_bins\": action_bins,\n",
    "              \"Q_bins\": obs_bins,\n",
    "              \"Q_table\": Q_table}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70519fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_sim(sim_params):\n",
    "    \n",
    "    env = sim_params[\"env\"]\n",
    "    no_epochs = sim_params[\"no_epochs\"]\n",
    "    no_iterations = sim_params[\"no_iterations\"]\n",
    "    no_oberservation_bins = sim_params[\"no_oberservation_bins\"]\n",
    "    no_actions_bins = sim_params[\"no_actions_bins\"]\n",
    "    epsilon = sim_params[\"epsilon\"]\n",
    "    action_bins = sim_params[\"action_bins\"]\n",
    "    Q_bins = sim_params[\"Q_bins\"]\n",
    "    Q_table = sim_params[\"Q_table\"]\n",
    "    \n",
    "    reward_values_per_epoch = []\n",
    "\n",
    "    for epoch in range(no_epochs):\n",
    "        observation, info = env.reset()\n",
    "        total_reward = 0\n",
    "        action_values = []\n",
    "        reward_values = []\n",
    "\n",
    "        for i in range(no_iterations):\n",
    "            discrete_state = discretize_state(observation, Q_bins)\n",
    "\n",
    "            epsilon_adj = epsilon - epsilon * (epoch / no_epochs)\n",
    "\n",
    "            if np.random.uniform() < epsilon_adj:\n",
    "                action = env.action_space.sample()\n",
    "                action_index = np.digitize(env.action_space.sample(),\n",
    "                                jnp.linspace(env.action_space.low[0], env.action_space.high[0], no_actions_bins))\n",
    "            else:\n",
    "                action_index = np.argmax(Q_table[discrete_state])\n",
    "                action = action_bins[action_index]\n",
    "\n",
    "            for _ in range(5):\n",
    "                observation, reward, terminated, truncated, info = env.step([action])\n",
    "            total_reward += reward\n",
    "            discrete_new_state = discretize_state(observation, Q_bins)\n",
    "\n",
    "            maxFutureQ = np.max(Q_table[discrete_new_state])  # estimate of optiomal future value\n",
    "            currentQ = Q_table[discrete_state + (action_index,)]  # old value\n",
    "\n",
    "            Q_value_new = 0.9 * currentQ + 0.1 * (reward + 0.9 * maxFutureQ)\n",
    "            Q_table[discrete_state + (action_index, )] = Q_value_new  # Update qTable with new Q value\n",
    "\n",
    "            action_values.append(action)\n",
    "            reward_values.append(total_reward)\n",
    "\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        \n",
    "        reward_values_per_epoch.append(reward_values)\n",
    "\n",
    "        if epoch % 10 == 0 and epoch > 1:\n",
    "            print(f\"Terminated after {i} iterations, reward: {total_reward}, epoch: {epoch}, eps: {epsilon_adj}\")\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "            ax1.plot(action_values)\n",
    "            ax1.set_title(\"action values\")\n",
    "            padded_values = np.array(list(zip_longest(*reward_values_per_epoch, fillvalue=0)))\n",
    "            ax2.plot(np.mean(padded_values, axis=1))\n",
    "            ax2.set_title(\"reward values\")\n",
    "            ax3.imshow(jnp.max(Q_table, axis=2), cmap='hot', interpolation='nearest')\n",
    "            ax3.set_title(\"state values\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            reward_values_per_epoch = []\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37625bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run_sim(sim_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5720d1bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbccdd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
